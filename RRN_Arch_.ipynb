{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d898c41-038f-466f-9884-69ec9564800d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4966713b-5011-48a7-9212-3b70ae83d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import functools\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import skimage.filters\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.ndimage.filters as fi\n",
    "\n",
    "from itertools import tee\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras import Model\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b50cfb-472d-4337-8fe4-0aaf4e357e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset Notes:\n",
    "\n",
    "* Dataset length = 144,682 sequence\n",
    "* Each sequence = 7 frames\n",
    "* Each frame = 256 x 256 x 3 \n",
    "* This is our Ground Truth dataset and it will be downsampled on the fly to train the model\n",
    "\n",
    "### Dataset splitting: \n",
    "* Train = 90,682     \n",
    "* Test = 27,000     \n",
    "* Validation = 27,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec66e7-0e76-4d73-987a-e8f449be374b",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac08439-bd49-408f-b76e-dcc2949c7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(sequence_path):\n",
    "    GT = [Image.open(sequence_path + str(img) + '.png') for img in range(7)]\n",
    "    return GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb2ffb-0606-4ebb-b952-c180e0cbe9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkern(kernlen=13, nsig=1.6):\n",
    "    inp = np.zeros((kernlen, kernlen))\n",
    "    # set element at the middle to one, a dirac delta\n",
    "    inp[kernlen // 2, kernlen // 2] = 1\n",
    "    # gaussian-smooth the dirac, resulting in a gaussian filter mask\n",
    "    return fi.gaussian_filter(inp, nsig)\n",
    "\n",
    "def Gaussian_down_sample(sequence, scale):\n",
    "    \"\"\"\n",
    "        sequence sahpe : [F, H, W, C]\n",
    "    \"\"\"\n",
    "    assert scale in[2, 4], \"Enter valid scale value [2, 4]\"\n",
    "    \n",
    "    nsigma = scale * 0.4\n",
    "    kernal_in = gkern()\n",
    "    gauss_kernel_2d = tf.convert_to_tensor(kernal_in, dtype=tf.float32)\n",
    "    gauss_kernel = tf.tile(gauss_kernel_2d[:, :, tf.newaxis, tf.newaxis], [1, 1, 3, 3]) # 13*13*3*3\n",
    "    \n",
    "    pad_w, pad_h = 6, 6   # Filter padding\n",
    "    padded_sequence = tf.pad(sequence, [[0,0], [pad_w,pad_w], [pad_h,pad_h], [0,0]], mode='REFLECT')\n",
    "    \n",
    "    # Pointwise filter that does nothing\n",
    "    pointwise_filter = tf.eye(3, batch_shape=[1, 1])\n",
    "    LR_seq = tf.nn.separable_conv2d(padded_sequence, gauss_kernel, pointwise_filter,\n",
    "                                    strides=[1, scale, scale, 1], padding=[[0,0],[0,0],[0,0],[0,0]])\n",
    "    return LR_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74486b2-4e99-45b2-ac54-a17077003442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator(train_dataset_path, batch_size, scale_factor):\n",
    "    train_sequences_count = 90682\n",
    "    train_batches_count = train_sequences_count // batch_size\n",
    "    train_batches = np.random.choice(np.arange(train_sequences_count), (train_batches_count, batch_size), replace=False)\n",
    "\n",
    "\n",
    "#     validation_sequences_count = 27000\n",
    "#     validation_batches_count = validation_sequences_count // batch_size\n",
    "#     validation_batches = np.random.choice(np.arange(validation_sequences_count), (validation_batches_count, batch_size), replace=False)\n",
    "    \n",
    "    sequence_len = 7\n",
    "    \n",
    "    # Now lets loop over the full epoch and process each batch befor return it to the network\n",
    "    for batch in train_batches:\n",
    "        GT_batch = []\n",
    "        LR_batch = []\n",
    "        for sequence in batch:\n",
    "            sequences_path = train_dataset_path + str('%05d'%sequence) + '/'\n",
    "            GT = load_sequence(sequences_path)\n",
    "            GT = [np.asarray(img) for img in GT]\n",
    "            GT = tf.cast(tf.convert_to_tensor(GT), tf.float32)\n",
    "            LR = Gaussian_down_sample(GT, scale_factor)\n",
    "            LR = tf.concat([LR[1:2, :, :, :], LR], axis=0)\n",
    "            GT_batch.append(GT)\n",
    "            LR_batch.append(LR)\n",
    "\n",
    "        yield np.array(GT_batch), np.array(LR_batch), train_batches_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072da41f-4971-42f3-944c-ff14391fdda9",
   "metadata": {},
   "source": [
    "## Subclassed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4e9b2c-979a-4585-b6bc-7511c27d3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the Residual Blocks\n",
    "def make_layer(block, n_layers):\n",
    "    layers = []\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(block())\n",
    "    return tf.keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294d0d34-43f8-43e6-af17-5e9cff877125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Blocks \n",
    "class Residual_Blocks(tf.keras.Model):\n",
    "    '''Residual block w/o BN\n",
    "    -+-Conv-ReLU-Conv-+-\n",
    "     |________________|\n",
    "    '''\n",
    "    def __init__(self, n_f):\n",
    "        super(Residual_Blocks, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=n_f, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.conv2 = Conv2D(filters=n_f, kernel_size=(3,3), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        \n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        return out + identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b31634-2881-4b5d-a22f-2e3a4f913d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers of the network\n",
    "class hidden(tf.keras.Model):\n",
    "    def __init__(self, n_f, n_b, scale):\n",
    "        super(hidden, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=n_f, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        basic_block = functools.partial(Residual_Blocks, n_f=n_f)\n",
    "        self.residual_blocks = make_layer(basic_block, n_b)\n",
    "        self.conv_h = Conv2D(filters=n_f, kernel_size=(3,3), activation='relu', padding='same', name='hidden_state', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.conv_o = Conv2D(filters=scale*scale*3, kernel_size=(3,3), padding='same', name='output', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        \n",
    "    def call(self, X, h, o):\n",
    "        x_input = tf.concat([X, tf.cast(h, tf.float32), tf.cast(o, tf.float32)], axis=-1)\n",
    "        x = self.conv1(x_input)\n",
    "        x = self.residual_blocks(x)\n",
    "        x_h = self.conv_h(x)\n",
    "        x_o = self.conv_o(x)\n",
    "        return x_h, x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743e4ee7-3d2e-4ae1-8b05-99f1ffc8f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down smaple the input\n",
    "class PixelUnShuffle(tf.keras.Model):\n",
    "    def __init__(self, scale):\n",
    "        super(PixelUnShuffle, self).__init__()\n",
    "        self.scale_factor = scale\n",
    "    \n",
    "    def call(self, x_o):\n",
    "        x_o = tf.nn.space_to_depth(x_o, self.scale_factor)\n",
    "        return x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a488c0-6e4d-44de-8add-cbdba146f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class\n",
    "class RRN(tf.keras.Model):\n",
    "    def __init__(self, n_f, n_b, scale):\n",
    "        super(RRN, self).__init__()\n",
    "        self.hidden = hidden(n_f, n_b, scale)\n",
    "        self.scale = scale\n",
    "        self.down = PixelUnShuffle(scale)\n",
    "        self.n_f = n_f\n",
    "        \n",
    "    def call(self, x, x_h, x_o, init):\n",
    "        f1 = x[:,0,:,:,:]\n",
    "        f2 = x[:,1,:,:,:]\n",
    "        h,w = f1.shape[1:3]\n",
    "        x_input = tf.concat([f1, f2], axis=-1)\n",
    "        if init:\n",
    "            x_h, x_o = self.hidden(x_input, x_h, x_o)\n",
    "        else:\n",
    "            x_o = self.down(x_o)\n",
    "            x_h, x_o = self.hidden(x_input, x_h, x_o)\n",
    "        \n",
    "        x_o = tf.image.resize(f2, (h*self.scale, w*self.scale)) + tf.nn.depth_to_space(x_o, self.scale)\n",
    "        return x_h, x_o\n",
    "    \n",
    "    def train_step(self, GT, LR, loss_fn, optimizer):\n",
    "        B,F,_,_,_ = LR.shape\n",
    "        output = []\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            for frame_index in range(F-1):\n",
    "                if not bool(frame_index):\n",
    "                    # Initialize frame[-1], hidden_state[-1] and prediction[-1]\n",
    "                    init_frame = tf.zeros_like(LR[:,0,:,:,:])\n",
    "                    prediction = tf.repeat(init_frame, repeats= self.scale**2, axis=3)\n",
    "                    hidden_state = tf.repeat(init_frame[:,:,:,:1], repeats= self.n_f, axis=-1)\n",
    "\n",
    "                hidden_state, prediction = self(LR[:,frame_index:frame_index+2,:,:,:], hidden_state, prediction, not bool(frame_index))\n",
    "                output.append(prediction)\n",
    "                \n",
    "            output = tf.stack(output, axis=1)\n",
    "            loss = tf.reduce_sum(loss_fn(GT, output))/(B*7)\n",
    "            gradients = tape.gradient(loss, self.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "            \n",
    "        return output, loss\n",
    "    \n",
    "    def plot_GT_pred(self, GT, pred):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 15))\n",
    "        axs[0].imshow(tf.cast(GT[0,0], tf.uint8))\n",
    "        axs[0].title.set_text('Ground Truth')\n",
    "        axs[1].imshow(tf.cast(pred[0,0], tf.uint8))\n",
    "        axs[1].title.set_text('Network output')\n",
    "        plt.show()\n",
    "        \n",
    "    def fit(self, data_generator, epochs, batch_size, loss_fn, optimizer, load_from_check_point = False):\n",
    "        if load_from_check_point:\n",
    "            self.load_weights('check_point/model_weights')\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            data_generator, data_gen = tee(data_generator)\n",
    "            for batch_index, data in enumerate(data_gen):\n",
    "                t0 = time.time()\n",
    "                \n",
    "                GT, LR, total_batches_count = data[0], data[1], data[2]\n",
    "                prediction, batch_loss = self.train_step(GT, LR, loss_fn, optimizer)\n",
    "                \n",
    "                # self.plot_GT_pred(GT, prediction)\n",
    "                if batch_index%20 == 0:\n",
    "                    self.save_weights('check_point/model_weights')  \n",
    "                    \n",
    "                t1 = time.time()\n",
    "                \n",
    "                print(\"Epoch[{}/{}],({}/{}): Batch_Loss: {:.4f} || Timer: {:.4f} sec.\".\n",
    "                format(epoch, epochs, (batch_index+1),total_batches_count, batch_loss, (t1-t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97ab3d-0a9c-416c-8cdb-9d182e3be7c1",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf95360-a6dd-4e31-808d-e887cf6b7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment variables\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "scale_factor = 4\n",
    "n_f = 128\n",
    "n_b = 5\n",
    "GT_path = 'Vimeo90k_256/train/'\n",
    "input_shape = (64, 64, 118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b77439-e485-4712-969e-c2ed8add53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5],(1/2833): Batch_Loss: 5701515608064.0000 || Timer: 8.3632 sec.\n",
      "Epoch[0/5],(2/2833): Batch_Loss: 894391156736.0000 || Timer: 8.3560 sec.\n",
      "Epoch[0/5],(3/2833): Batch_Loss: 341150105600.0000 || Timer: 8.4944 sec.\n",
      "Epoch[0/5],(4/2833): Batch_Loss: 177878106112.0000 || Timer: 8.5013 sec.\n",
      "Epoch[0/5],(5/2833): Batch_Loss: 105108463616.0000 || Timer: 8.7005 sec.\n",
      "Epoch[0/5],(6/2833): Batch_Loss: 65573650432.0000 || Timer: 8.5317 sec.\n",
      "Epoch[0/5],(7/2833): Batch_Loss: 54557921280.0000 || Timer: 8.6683 sec.\n",
      "Epoch[0/5],(8/2833): Batch_Loss: 36014542848.0000 || Timer: 8.4122 sec.\n",
      "Epoch[0/5],(9/2833): Batch_Loss: 35948769280.0000 || Timer: 8.4894 sec.\n",
      "Epoch[0/5],(10/2833): Batch_Loss: 24839538688.0000 || Timer: 8.6573 sec.\n",
      "Epoch[0/5],(11/2833): Batch_Loss: 24162465792.0000 || Timer: 8.6831 sec.\n",
      "Epoch[0/5],(12/2833): Batch_Loss: 20452900864.0000 || Timer: 8.7176 sec.\n",
      "Epoch[0/5],(13/2833): Batch_Loss: 17302509568.0000 || Timer: 8.4940 sec.\n",
      "Epoch[0/5],(14/2833): Batch_Loss: 13272921088.0000 || Timer: 8.4635 sec.\n",
      "Epoch[0/5],(15/2833): Batch_Loss: 13207510016.0000 || Timer: 8.7630 sec.\n",
      "Epoch[0/5],(16/2833): Batch_Loss: 9230609408.0000 || Timer: 8.7681 sec.\n",
      "Epoch[0/5],(17/2833): Batch_Loss: 8589182464.0000 || Timer: 8.5424 sec.\n",
      "Epoch[0/5],(18/2833): Batch_Loss: 8265499136.0000 || Timer: 8.4968 sec.\n",
      "Epoch[0/5],(19/2833): Batch_Loss: 7743613440.0000 || Timer: 8.5006 sec.\n",
      "Epoch[0/5],(20/2833): Batch_Loss: 6393389568.0000 || Timer: 8.4875 sec.\n",
      "Epoch[0/5],(21/2833): Batch_Loss: 5470434304.0000 || Timer: 8.6315 sec.\n",
      "Epoch[0/5],(22/2833): Batch_Loss: 5297813504.0000 || Timer: 8.6045 sec.\n",
      "Epoch[0/5],(23/2833): Batch_Loss: 4831855616.0000 || Timer: 8.7575 sec.\n",
      "Epoch[0/5],(24/2833): Batch_Loss: 4688469504.0000 || Timer: 8.6612 sec.\n",
      "Epoch[0/5],(25/2833): Batch_Loss: 4744948736.0000 || Timer: 8.6050 sec.\n",
      "Epoch[0/5],(26/2833): Batch_Loss: 3921730048.0000 || Timer: 8.6815 sec.\n",
      "Epoch[0/5],(27/2833): Batch_Loss: 3888241920.0000 || Timer: 8.4409 sec.\n",
      "Epoch[0/5],(28/2833): Batch_Loss: 3858315264.0000 || Timer: 8.5396 sec.\n",
      "Epoch[0/5],(29/2833): Batch_Loss: 3137210112.0000 || Timer: 8.3401 sec.\n",
      "Epoch[0/5],(30/2833): Batch_Loss: 2946260224.0000 || Timer: 8.5574 sec.\n",
      "Epoch[0/5],(31/2833): Batch_Loss: 2693007360.0000 || Timer: 8.3918 sec.\n",
      "Epoch[0/5],(32/2833): Batch_Loss: 2709873920.0000 || Timer: 8.5646 sec.\n",
      "Epoch[0/5],(33/2833): Batch_Loss: 2575398656.0000 || Timer: 8.7052 sec.\n",
      "Epoch[0/5],(34/2833): Batch_Loss: 2137595136.0000 || Timer: 8.5572 sec.\n",
      "Epoch[0/5],(35/2833): Batch_Loss: 2590833408.0000 || Timer: 8.3216 sec.\n",
      "Epoch[0/5],(36/2833): Batch_Loss: 2067222912.0000 || Timer: 8.5015 sec.\n",
      "Epoch[0/5],(37/2833): Batch_Loss: 1897972992.0000 || Timer: 8.4506 sec.\n",
      "Epoch[0/5],(38/2833): Batch_Loss: 2178138112.0000 || Timer: 8.7266 sec.\n",
      "Epoch[0/5],(39/2833): Batch_Loss: 2003161728.0000 || Timer: 8.3427 sec.\n",
      "Epoch[0/5],(40/2833): Batch_Loss: 1453810304.0000 || Timer: 8.7654 sec.\n",
      "Epoch[0/5],(41/2833): Batch_Loss: 1666484352.0000 || Timer: 8.5849 sec.\n",
      "Epoch[0/5],(42/2833): Batch_Loss: 1532131072.0000 || Timer: 8.5460 sec.\n",
      "Epoch[0/5],(43/2833): Batch_Loss: 1429088896.0000 || Timer: 8.5538 sec.\n",
      "Epoch[0/5],(44/2833): Batch_Loss: 1570494336.0000 || Timer: 8.5512 sec.\n",
      "Epoch[0/5],(45/2833): Batch_Loss: 1318037888.0000 || Timer: 8.4898 sec.\n",
      "Epoch[0/5],(46/2833): Batch_Loss: 1355637120.0000 || Timer: 8.6519 sec.\n",
      "Epoch[0/5],(47/2833): Batch_Loss: 1313156480.0000 || Timer: 8.4174 sec.\n",
      "Epoch[0/5],(48/2833): Batch_Loss: 1253061120.0000 || Timer: 8.4927 sec.\n",
      "Epoch[0/5],(49/2833): Batch_Loss: 1225632640.0000 || Timer: 8.4192 sec.\n",
      "Epoch[0/5],(50/2833): Batch_Loss: 1253459584.0000 || Timer: 8.4750 sec.\n",
      "Epoch[0/5],(51/2833): Batch_Loss: 1237604736.0000 || Timer: 8.5668 sec.\n",
      "Epoch[0/5],(52/2833): Batch_Loss: 1224708096.0000 || Timer: 8.5582 sec.\n",
      "Epoch[0/5],(53/2833): Batch_Loss: 1077580288.0000 || Timer: 8.7483 sec.\n",
      "Epoch[0/5],(54/2833): Batch_Loss: 1002496000.0000 || Timer: 8.4442 sec.\n",
      "Epoch[0/5],(55/2833): Batch_Loss: 1002141312.0000 || Timer: 8.4190 sec.\n",
      "Epoch[0/5],(56/2833): Batch_Loss: 924914752.0000 || Timer: 8.5111 sec.\n",
      "Epoch[0/5],(57/2833): Batch_Loss: 947536384.0000 || Timer: 8.4805 sec.\n",
      "Epoch[0/5],(58/2833): Batch_Loss: 853152000.0000 || Timer: 8.6302 sec.\n",
      "Epoch[0/5],(59/2833): Batch_Loss: 909368192.0000 || Timer: 8.3160 sec.\n",
      "Epoch[0/5],(60/2833): Batch_Loss: 872482432.0000 || Timer: 8.2797 sec.\n",
      "Epoch[0/5],(61/2833): Batch_Loss: 767132416.0000 || Timer: 8.8999 sec.\n",
      "Epoch[0/5],(62/2833): Batch_Loss: 881806208.0000 || Timer: 8.4688 sec.\n",
      "Epoch[0/5],(63/2833): Batch_Loss: 799329472.0000 || Timer: 8.5086 sec.\n",
      "Epoch[0/5],(64/2833): Batch_Loss: 781968256.0000 || Timer: 8.4966 sec.\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.mae\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=1e-4, weight_decay=5e-4)\n",
    "model = RRN(n_f, n_b, scale_factor)\n",
    "data_gen = train_data_generator(GT_path, batch_size, scale_factor)\n",
    "model.fit(data_gen, epochs, batch_size, loss_fn, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
